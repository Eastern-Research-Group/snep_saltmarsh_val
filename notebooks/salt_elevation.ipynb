{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate 30-, 60-, and 90- day inundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Woods Hole Gauge\n",
    "wh_path = \"../data/raw/water_levels/woods_hole/\"\n",
    "wh_files = glob.glob(wh_path + \"/*.csv\")\n",
    "\n",
    "# Conimicut Light Gauge\n",
    "cl_path = \"../data/raw/water_levels/conimicut_light/\"\n",
    "cl_files = glob.glob(cl_path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How SLAMM model creator, Jonathan Clough, described how they calculated the salt elevation: What we have done is take maximum daily water levels for several years (either from maximum daily levels or the maximum of hourly observed) and then taken the 96.7 percentile of those data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_salt_elev(wl_files: list, quant_num):\n",
    "    \n",
    "    # read in the data\n",
    "    wl_data = pd.concat((pd.read_csv(f) for f in wl_files), ignore_index=True)\n",
    "    print(wl_data)\n",
    "\n",
    "    # Convert date column to date time\n",
    "    wl_data.Date = pd.to_datetime(wl_data.Date)\n",
    "    wl_data = wl_data[wl_data[\"Verified (m)\"] != '-']\n",
    "    wl_data[\"Verified (m)\"] = wl_data[\"Verified (m)\"].astype(float)\n",
    "    \n",
    "    # Simplify to the columns needed\n",
    "    wl_ver = wl_data[[\"Date\", \"Verified (m)\"]]\n",
    "    print(wl_data[[\"Date\"]].min())\n",
    "    print(wl_data[[\"Date\"]].max())\n",
    "\n",
    "    # Set the index as the date\n",
    "    wl_ver = wl_ver.set_index(\"Date\")\n",
    "\n",
    "    # Daily maximum water level\n",
    "    mx_day = wl_ver.groupby(pd.Grouper(freq=\"D\")).max()\n",
    "    mx_day\n",
    "\n",
    "    quant_want = mx_day.quantile(quant_num)\n",
    "\n",
    "    return quant_want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woodshole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date Time (GMT)  Predicted (m) Preliminary (m)  Verified (m)\n",
      "0      2019/01/01      00:00         -0.038               -         0.104\n",
      "1      2019/01/01      01:00         -0.094               -         0.092\n",
      "2      2019/01/01      02:00         -0.189               -         0.067\n",
      "3      2019/01/01      03:00         -0.268               -         0.040\n",
      "4      2019/01/01      04:00         -0.317               -         0.000\n",
      "...           ...        ...            ...             ...           ...\n",
      "43819  2023/09/30      19:00         -0.219               -        -0.053\n",
      "43820  2023/09/30      20:00         -0.335               -        -0.149\n",
      "43821  2023/09/30      21:00         -0.370               -        -0.188\n",
      "43822  2023/09/30      22:00         -0.296               -        -0.100\n",
      "43823  2023/09/30      23:00         -0.103               -         0.089\n",
      "\n",
      "[43824 rows x 5 columns]\n",
      "Date   2019-01-01\n",
      "dtype: datetime64[ns]\n",
      "Date   2023-12-31\n",
      "dtype: datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Verified (m)    0.80055\n",
       "Name: 0.967, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30 day inundation\n",
    "calc_salt_elev(wh_files, 0.967)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date Time (GMT)  Predicted (m) Preliminary (m)  Verified (m)\n",
      "0      2019/01/01      00:00         -0.038               -         0.104\n",
      "1      2019/01/01      01:00         -0.094               -         0.092\n",
      "2      2019/01/01      02:00         -0.189               -         0.067\n",
      "3      2019/01/01      03:00         -0.268               -         0.040\n",
      "4      2019/01/01      04:00         -0.317               -         0.000\n",
      "...           ...        ...            ...             ...           ...\n",
      "43819  2023/09/30      19:00         -0.219               -        -0.053\n",
      "43820  2023/09/30      20:00         -0.335               -        -0.149\n",
      "43821  2023/09/30      21:00         -0.370               -        -0.188\n",
      "43822  2023/09/30      22:00         -0.296               -        -0.100\n",
      "43823  2023/09/30      23:00         -0.103               -         0.089\n",
      "\n",
      "[43824 rows x 5 columns]\n",
      "Date   2019-01-01\n",
      "dtype: datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Verified (m)    0.854\n",
       "Name: 0.983, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60 day - 0.983\n",
    "calc_salt_elev(wh_files, 0.983)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date Time (GMT)  Predicted (m) Preliminary (m)  Verified (m)\n",
      "0      2019/01/01      00:00         -0.038               -         0.104\n",
      "1      2019/01/01      01:00         -0.094               -         0.092\n",
      "2      2019/01/01      02:00         -0.189               -         0.067\n",
      "3      2019/01/01      03:00         -0.268               -         0.040\n",
      "4      2019/01/01      04:00         -0.317               -         0.000\n",
      "...           ...        ...            ...             ...           ...\n",
      "43819  2023/09/30      19:00         -0.219               -        -0.053\n",
      "43820  2023/09/30      20:00         -0.335               -        -0.149\n",
      "43821  2023/09/30      21:00         -0.370               -        -0.188\n",
      "43822  2023/09/30      22:00         -0.296               -        -0.100\n",
      "43823  2023/09/30      23:00         -0.103               -         0.089\n",
      "\n",
      "[43824 rows x 5 columns]\n",
      "Date   2019-01-01\n",
      "dtype: datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Verified (m)    0.871925\n",
       "Name: 0.989, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90 day - 0.989\n",
    "calc_salt_elev(wh_files, 0.989)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Conimicut Light Gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date Time (GMT)  Predicted (m) Preliminary (m) Verified (m)\n",
      "0      2019/01/01      00:00         -0.342               -       -0.093\n",
      "1      2019/01/01      01:00         -0.538               -       -0.337\n",
      "2      2019/01/01      02:00         -0.585               -       -0.394\n",
      "3      2019/01/01      03:00         -0.555               -       -0.206\n",
      "4      2019/01/01      04:00         -0.519               -        0.014\n",
      "...           ...        ...            ...             ...          ...\n",
      "43819  2023/09/30      19:00         -0.763               -            -\n",
      "43820  2023/09/30      20:00         -0.675               -            -\n",
      "43821  2023/09/30      21:00         -0.538               -            -\n",
      "43822  2023/09/30      22:00         -0.308               -            -\n",
      "43823  2023/09/30      23:00          0.071               -            -\n",
      "\n",
      "[43824 rows x 5 columns]\n",
      "Date   2019-01-01\n",
      "dtype: datetime64[ns]\n",
      "Date   2023-12-31\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "cl_30 = calc_salt_elev(cl_files, 0.967)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 day inundation\n",
    "cl_30 = calc_salt_elev(cl_files, 0.967)\n",
    "\n",
    "# 60 day - 0.983\n",
    "cl_60 = calc_salt_elev(cl_files, 0.983)\n",
    "\n",
    "# 90 day - 0.989\n",
    "cl_90 = calc_salt_elev(cl_files, 0.989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 day:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Verified (m)    1.192\n",
       "Name: 0.967, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('30 day:')\n",
    "cl_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 day:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Verified (m)    1.242148\n",
       "Name: 0.983, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('60 day:')\n",
    "cl_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 day:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Verified (m)    1.275488\n",
       "Name: 0.989, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('90 day:')\n",
    "cl_90"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
